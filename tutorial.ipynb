{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tqdm.notebook as tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Root Files Into Pandas Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace this with a path to the WC ntuple files\n",
    "wc_file_location = \"/Users/leehagaman/data/processed_checkout_rootfiles/\"\n",
    "\n",
    "# let's open a nu_overlay file and examine the contents\n",
    "\n",
    "f_nu_overlay = uproot.open(wc_file_location + \"checkout_prodgenie_bnb_nu_overlay_run1_PF.root\")\n",
    "f_nu_overlay.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see that there are several TTrees inside the wcpselection TDirectory. Now let's print the variables in each TTree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_printed_keys = []\n",
    "\n",
    "for key in f_nu_overlay[\"wcpselection\"].items():\n",
    "    key_name = key[0].split(\";\")[0]\n",
    "    if key_name not in already_printed_keys: # sometimes a TTree is repeated, we ignore duplicates\n",
    "        print(\"\\nPrinting variables in TTree: \", key[0].split(\";\")[0])\n",
    "        print(f_nu_overlay[\"wcpselection\"][key[0]].keys())\n",
    "        already_printed_keys.append(key_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's a lot of variables! Let's only load a few of the most relevant ones for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Variables To Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_bdt_vars = [              # variables involved with BDT training\n",
    "    \"nue_score\",                    # BDT score for nue selection, used for the WC inclusive nueCC analysis\n",
    "    \"numu_score\",                   # BDT score for numu selection, used for the WC inclusive numuCC selections\n",
    "]\n",
    "\n",
    "T_eval_vars = [             # variables involved with low level reconstruction and truth information\n",
    "    \"run\",                          # run number\n",
    "    \"subrun\",                       # subrun number\n",
    "    \"event\",                        # event number\n",
    "    \"match_isFC\",                   # reconstructed cluster is fully contained (FC), boolean\n",
    "    \"truth_nuEnergy\",               # true neutrino energy (MeV)\n",
    "    \"truth_nuPdg\",                  # true neutrino pdg code\n",
    "    \"truth_isCC\",                   # true interaction type is charged current, boolean\n",
    "    \"match_completeness_energy\",    # the true energy deposited in the clusters that are 3D-matched with the reconstructed neutrino clusters (MeV)\n",
    "    \"truth_energyInside\",           # the true energy deposited in the TPC Fiducial Volume (MeV)\n",
    "    \"truth_vtxInside\",              # boolean, true neutrino vertex is inside the TPC Fiducial Volume\n",
    "    \"truth_vtxX\",                   # true neutrino vertex x (cm)\n",
    "    \"truth_vtxY\",                   # true neutrino vertex y (cm)\n",
    "    \"truth_vtxZ\",                   # true neutrino vertex z (cm)\n",
    "    \"weight_cv\",                    # untuned GENIE event weight\n",
    "    \"weight_spline\",                # additional MicroBooNE Tune weight\n",
    "]\n",
    "T_eval_data_vars = [        # same as above, but for data files we do not attempt to load any truth information\n",
    "    \"match_isFC\",\n",
    "]\n",
    "\n",
    "T_kine_vars = [             # variables involved with kinematic reconstruction\n",
    "    \"kine_reco_Enu\",                # reconstructed neutrino energy (MeV)   \n",
    "]\n",
    "\n",
    "T_pf_vars = [               # variables involved with individual particles\n",
    "    \"truth_NprimPio\",\n",
    "    \"truth_NCDelta\",\n",
    "    \"reco_nuvtxX\",\n",
    "    \"reco_nuvtxY\",\n",
    "    \"reco_nuvtxZ\",\n",
    "    \"reco_muonMomentum\",            # reconstructed muon momentum 4-vector (p_x, p_y, p_z, p_t), in (GeV/c, GeV/c, GeV/c, GeV)\n",
    "\n",
    "    # These variables are related to individual true particles\n",
    "    \"truth_Ntrack\",\n",
    "    \"truth_id\",\n",
    "    \"truth_pdg\",\n",
    "    \"truth_mother\",\n",
    "    \"truth_startMomentum\",\n",
    "    \"truth_startXYZT\",\n",
    "\n",
    "    # These variables are related to individual reco particles\n",
    "    \"reco_Ntrack\",\n",
    "    \"reco_id\",\n",
    "    \"reco_pdg\",\n",
    "    \"reco_mother\",\n",
    "    \"reco_startMomentum\",\n",
    "    \"reco_startXYZT\",\n",
    "]\n",
    "T_pf_data_vars = [          # same as above, but for data files we do not attempt to load any truth information\n",
    "    \"reco_nuvtxX\",\n",
    "    \"reco_nuvtxY\",\n",
    "    \"reco_nuvtxZ\",\n",
    "    \"reco_muonMomentum\",\n",
    "    \"reco_Ntrack\",\n",
    "    \"reco_id\",\n",
    "    \"reco_pdg\",\n",
    "    \"reco_mother\",\n",
    "    \"reco_startMomentum\",\n",
    "    \"reco_startXYZT\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading nu_overlay File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_nu_overlay = uproot.open(wc_file_location + \"checkout_prodgenie_bnb_nu_overlay_run1_PF.root\") # loading the nu_overlay file\n",
    "\n",
    "# loading variables from each TTree\n",
    "nu_overlay_bdt_df = f_nu_overlay[\"wcpselection\"][\"T_BDTvars\"].arrays(T_bdt_vars, library=\"pd\")\n",
    "nu_overlay_eval_df = f_nu_overlay[\"wcpselection\"][\"T_eval\"].arrays(T_eval_vars, library=\"pd\")\n",
    "nu_overlay_kine_df = f_nu_overlay[\"wcpselection\"][\"T_KINEvars\"].arrays(T_kine_vars, library=\"pd\")\n",
    "nu_overlay_pf_df = f_nu_overlay[\"wcpselection\"][\"T_PFeval\"].arrays(T_pf_vars, library=\"pd\")\n",
    "\n",
    "# combining everything into a single dataframe\n",
    "nu_overlay_df = pd.concat([nu_overlay_bdt_df, nu_overlay_eval_df, nu_overlay_kine_df, nu_overlay_pf_df], axis=1)\n",
    "\n",
    "# deleting temporary dataframes to free up memory\n",
    "del nu_overlay_bdt_df, nu_overlay_eval_df, nu_overlay_kine_df, nu_overlay_pf_df\n",
    "\n",
    "nu_overlay_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data, Dirt, and EXT files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making A Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting An Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle-level Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
